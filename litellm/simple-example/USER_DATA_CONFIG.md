# Maximum User Data Capture Configuration

This directory contains an enhanced LiteLLM configuration that captures **all possible user information** from OpenWebUI and forwards it to Langfuse for comprehensive tracking and analytics.

## üöÄ Enhanced Features

### User Identity Tracking
- **Primary User ID**: `X-OpenWebUI-User-Email` (configurable)
- **Secondary User ID**: `X-OpenWebUI-User-Id` (via user_api_key_alias)
- **User Name**: `X-OpenWebUI-User-Name`
- **User Role**: `X-OpenWebUI-User-Role`

### Session & Context Tracking
- **Session ID**: `X-OpenWebUI-Session-Id`
- **Chat ID**: `X-OpenWebUI-Chat-Id`
- **Model Used**: `X-OpenWebUI-Model`
- **Chat Title**: `X-OpenWebUI-Title`

### Enhanced Debugging
- **Verbose Logging**: See all headers and requests
- **Detailed Debug**: Comprehensive request/response logging
- **Rich Metadata**: All headers captured as Langfuse metadata

## üìÅ Configuration Files

### config.yaml
Enhanced LiteLLM configuration with:
```yaml
general_settings:
  user_header_name: X-OpenWebUI-User-Email    # Primary user identifier
  user_api_key_alias: X-OpenWebUI-User-Id     # Secondary identifier
  detailed_debug: true                         # Enable detailed logging

litellm_settings:
  success_callback: ["langfuse"]               # Send successful requests to Langfuse
  failure_callback: ["langfuse"]               # Send failed requests to Langfuse
  set_verbose: true                            # Verbose logging
  
  # Capture ALL OpenWebUI headers as metadata
  extra_spend_tag_headers:
    - "X-OpenWebUI-User-Name"
    - "X-OpenWebUI-User-Id" 
    - "X-OpenWebUI-User-Role"
    - "X-OpenWebUI-User-Email"
    - "X-OpenWebUI-Session-Id"
    - "X-OpenWebUI-Chat-Id"
    - "X-OpenWebUI-Model"
    - "X-OpenWebUI-Title"
```

### Test Scripts
- **`test_user_proxy.py`**: Tests user data forwarding to Langfuse
- **`test_enhanced_config.py`**: Tests the enhanced configuration
- **`test_langfuse_connection.py`**: Basic Langfuse connectivity test

## üîß Setup Instructions

### 1. OpenWebUI Configuration
Ensure your OpenWebUI has user header forwarding enabled:
```yaml
environment:
  - ENABLE_FORWARD_USER_INFO_HEADERS=true
```

### 2. Environment Variables
Make sure these are set in your `.env` file:
```bash
LANGFUSE_PUBLIC_KEY=pk-lf-your-key
LANGFUSE_SECRET_KEY=sk-lf-your-secret
LANGFUSE_HOST=https://your-langfuse-instance.com
LITELLM_MASTER_KEY=your-master-key
OPENROUTER_API_KEY=your-openrouter-key
```

### 3. Start LiteLLM
```bash
# Using the enhanced config
litellm --config config.yaml --port 4000

# Or use the provided start script
./start.sh
```

### 4. Test the Configuration
```bash
# Test basic connectivity
./test_langfuse.sh

# Test user data forwarding
python test_user_proxy.py

# Test enhanced configuration
python test_enhanced_config.py
```

## üìä What Gets Tracked in Langfuse

With this configuration, every request will include:

### User Attribution
- **User Email**: Primary identifier for user tracking
- **User ID**: Unique user identifier
- **User Name**: Display name
- **User Role**: Permission level (user, admin, etc.)

### Session Context
- **Session ID**: Groups related conversations
- **Chat ID**: Specific conversation thread
- **Chat Title**: Human-readable conversation name
- **Model**: Which AI model was used

### Request Metadata
- **Timestamps**: When requests occurred
- **Response Times**: Performance metrics
- **Success/Failure**: Error tracking
- **Token Usage**: Cost and usage analytics

### Example Langfuse Trace
```json
{
  "trace_id": "trace-123",
  "user_id": "test-user@example.com",
  "metadata": {
    "X-OpenWebUI-User-Name": "John Doe",
    "X-OpenWebUI-User-Id": "user-456",
    "X-OpenWebUI-User-Role": "admin",
    "X-OpenWebUI-Session-Id": "session-789",
    "X-OpenWebUI-Chat-Id": "chat-101",
    "X-OpenWebUI-Model": "gpt-4",
    "X-OpenWebUI-Title": "Project Planning Discussion"
  }
}
```

## üéØ Benefits

### For Administrators
- **User Analytics**: See who's using which models most
- **Cost Attribution**: Track spending per user/department
- **Usage Patterns**: Understand peak usage times
- **Error Tracking**: Monitor which users encounter issues

### For Users
- **Conversation History**: Rich context preservation
- **Cross-Session Continuity**: Link related conversations
- **Performance Insights**: See response times and quality

### For Development
- **Debug Information**: Detailed logging for troubleshooting
- **A/B Testing**: Compare different configurations
- **Performance Monitoring**: Track system health

## üîç Monitoring & Analytics

Access your Langfuse dashboard to see:
- Real-time request tracking
- User-segmented analytics
- Cost breakdowns by user/session
- Error rates and patterns
- Model performance comparisons

## üõ†Ô∏è Troubleshooting

### Check Headers Are Being Sent
Enable verbose logging and check LiteLLM logs:
```bash
docker logs litellm-litellm-1 -f
```

### Verify Langfuse Connection
```bash
python test_langfuse_connection.py
```

### Test User Data Flow
```bash
python test_user_proxy.py
```

### Common Issues
1. **Headers not appearing**: Check OpenWebUI has `ENABLE_FORWARD_USER_INFO_HEADERS=true`
2. **Langfuse connection fails**: Verify API keys and host URL
3. **No user attribution**: Ensure `user_header_name` matches sent headers
4. **Missing metadata**: Check `extra_spend_tag_headers` configuration

## üìà Next Steps

Once configured, you can:
1. Create Langfuse dashboards for your specific needs
2. Set up alerts for unusual usage patterns
3. Export data for further analysis
4. Integrate with other monitoring tools

This configuration provides the foundation for comprehensive AI interaction tracking and analytics!