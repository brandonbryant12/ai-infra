model_list:

- model_name: gpt-4-turbo
  litellm_params:
    model: openrouter/openai/gpt-4-turbo
    api_key: os.environ/OPENROUTER_API_KEY
    api_base: https://openrouter.ai/api/v1
    max_tokens: 128000
    temperature: 0.7
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0
    timeout: 60
    stream_timeout: 300
  model_info:
    mode: chat
    supports_function_calling: true
    supports_parallel_function_calling: true
    supports_vision: true

- model_name: claude-3-5-sonnet
  litellm_params:
    model: openrouter/anthropic/claude-3.5-sonnet
    api_key: os.environ/OPENROUTER_API_KEY
    api_base: https://openrouter.ai/api/v1
    max_tokens: 200000
    temperature: 0.7
    top_p: 1.0
    timeout: 60
    stream_timeout: 300
  model_info:
    mode: chat
    supports_function_calling: true
    supports_parallel_function_calling: true
    supports_vision: true

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  
  # Langfuse Integration
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]
  
  # Optional: Set budget limits
  max_budget: 100
  budget_duration: "1mo"
  
  # Optional: Rate limiting
  rpm: 600  # requests per minute
  tpm: 60000  # tokens per minute

# Langfuse callback configuration
litellm_settings:
  success_callback: ["langfuse"]
  failure_callback: ["langfuse"]
  langfuse_public_key: os.environ/LANGFUSE_PUBLIC_KEY
  langfuse_secret_key: os.environ/LANGFUSE_SECRET_KEY
  langfuse_host: os.environ/LANGFUSE_HOST

# Optional: Router settings for load balancing
router_settings:
  routing_strategy: "usage-based-routing-v2"
  model_group_alias: 
    gpt-4: ["gpt-4-turbo"]
    claude: ["claude-3-5-sonnet"]